# -*- coding: utf-8 -*-
"""Kaggle_Data_Challenge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h8Wqzc9TUXP6FMl0NBZm4w2xfU_y_gUn

# Predicting whether a DNA sequence (or read) belongs to the SARS-CoV-2 (Covid-19).

In this data challenge our goal is to implement machine learning algorithms to structural data, we have chosen a sequence classification task:short DNA fragments (~100 to 300bp long), that come from sequencing experiments, or that were simulated from full genomes. The goal is to discriminate the Covid-19 fragments, hence the task is a binary classification task: the labels are either 1 if the fragment is identified as Covid-19, and 0 otherwise.

## [Optuna](https://optuna.org/) 
- A hyperparameter optimization framework

## [cvxopt](https://cvxopt.org/) 
- A convex optimization package

### Installing and Importing the required Libraries
"""

# !pip install cvxopt -q
# !pip install optuna -q

import sklearn
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt



from sklearn.model_selection import train_test_split
from sklearn.preprocessing import scale
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score, precision_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics import roc_auc_score


import os
import optuna
import random
import cvxopt
import cvxopt.solvers
import sklearn

cvxopt.solvers.options['show_progress'] = False

"""### Read the dataset using pandas into the notebook for assess"""

np.random.seed(42)
random.seed(42)

# X_train1 = np.loadtxt('/content/Xtr.csv', skiprows=1, usecols=(1,), dtype=str, delimiter=',')
# y = np.loadtxt('/content/Ytr.csv', skiprows=1, usecols=(1,), dtype=int, delimiter=',')
# X_test1 = np.loadtxt('/content/Xte.csv', skiprows=1, usecols=(1,), dtype=str, delimiter=',')
# X_train_vectors1 = np.loadtxt('/content/Xtr_vectors.csv', skiprows=1, usecols=(), dtype=str, delimiter=',')
# X_test_vectors1 = np.loadtxt('/content/Xte_vectors.csv', skiprows=1, usecols=(), dtype=str, delimiter=',')
# X_full = np.hstack([X_train1, X_test1])
# y1 = 2*y - 1.

X_test_ = pd.read_csv('Xte.csv',sep=',',index_col=0)
X_train_ = pd.read_csv('Xtr.csv',sep=',',index_col=0)

X_test_vectors = pd.read_csv('Xte_vectors.csv',sep=' ',header=None).values
X_train_vectors = pd.read_csv('Xtr_vectors.csv',sep=' ',header=None).values

y = pd.read_csv('Ytr.csv',sep=',',index_col=0)

## Preview the dataset
X_test_

"""### Let's define function that will help us get the label into the format we want

- Label will be  0 or 1 if we use type=0
- label will be -1 or 1 if we use type=-1
"""

## Function for converting the label data from 0 and 1 to -1 and 1
def get_label(type=0):
    y = pd.read_csv('Ytr.csv',sep=',',index_col=0)
    if type == 0:
        y = y.Covid.values
        return y
    else:
        y['Covid'] = y.Covid.apply(lambda x: -1 if x == 0 else 1)
        y = y.Covid.values
        return y
    
get_label(-1).shape

"""### We write a funtion to split the data into test and train for validation"""

## Define a function to split the data 
def get_train_test(X,y,p):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=p, random_state=42)
    print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)
    return X_train, X_test, y_train, y_test

"""### Let's know more about the data we have"""

# The data review 
X_train_.head()

## The shape of the data
X_train_.shape

# THE DATA IS PROPORTIONAL DATA 
y['Covid'].value_counts().plot.bar()

# ADDITIONALLY ALL DATA CONTAINS 101 LENGTH SEQUENCES SO THERE WILL BE NO NEED OF PADDING 
X_train_['Count'] = X_train_.Sequence.apply(lambda x:len(x))
X_train_['Count'].value_counts().plot.bar()

# # Visualize training data
# def plot_data(X, y):
#     plt.figure(figsize=(8,7))
#     plt.scatter(X,y)
#     plt.xlabel('$x_1$')
#     plt.ylabel('$x_2$')
#     plt.show()
    
# plot_data(X_test_, y)

"""#  Data Related Experiments
---------------------------------------------------------

## K-mer counting/Spectral Embedding
--------------------------------------------------------


K-mer of size 3 

    'ACAAT' = ['aca', 'caa', 'aat']
"""

def getKmers(sequence, size=3):
    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]

def base2int(c):
    return {'a':0,'c':1,'g':2,'t':3}.get(c,0)

def index(kmer):
    base_idx = np.array([base2int(base) for base in kmer])
    multiplier = 4** np.arange(len(kmer))
    kmer_idx = multiplier.dot(base_idx)
    return kmer_idx

def spectral_embedding(sequence,kmer_size=3):
    kmers = getKmers(sequence,kmer_size)
    kmer_idxs = [index(kmer) for kmer in kmers]
    one_hot_vector = np.zeros(4**kmer_size)
    
    for kmer_idx in kmer_idxs:
        one_hot_vector[kmer_idx] += 1
    return one_hot_vector

def get_data(kmer_size):
    data = pd.DataFrame(pd.concat([X_train_.Sequence,X_test_.Sequence],axis=0))
    # data = pd.DataFrame(X_train_.Sequence)
    train_text = data.Sequence.values
    kmer_data = []
    for i in train_text:
        kmer_data.append(spectral_embedding(i,kmer_size=kmer_size))

    return np.array(kmer_data)

get_data(3).shape

X_test_.Sequence.shape

def get_count_grams(data,n=6):
    cv = CountVectorizer(analyzer='char',ngram_range=(n,n))
    X = cv.fit_transform(data).toarray()
    return X

def get_tf_idf_grams(data,n=6):
    cv = TfidfVectorizer(analyzer='char',ngram_range=(n,n))
    X = cv.fit_transform(data).toarray()
    return X

"""##  Logistic Regression 
Logistic regression model from scratch
"""

class logisticregression():
    def __init__(self,train_data,train_labels,lamda=0.2,lr=0.01,decay=10,batch_size=64,epoch=10,print_every = 10):
        dummy_once = np.ones((len(train_data),1))
        self.train_data = np.hstack((dummy_once,train_data))
        self.train_labels = train_labels
        
        self.params = np.zeros((len(self.train_data[0]),1))
        
        self.lr = lr
        self.epoch = epoch
        self.batch_size = batch_size
        self.print_every = print_every
        self._lambda = lamda
        self.decay = decay
        
    def sigmoid(self,x):
        return 1/(1+np.exp(-x))
    
    def cost(self,y,y_pred):
        return -np.mean(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))
    
    def gradient(self,y,y_pred,x):
        return np.dot(x.T,(y_pred-y))+(2*(self._lambda/len(self.train_labels ))*self.params)
    
    def train(self):
        for i in range(self.epoch):
            for j in range(len(self.train_labels)//self.batch_size):
                idx = list(np.random.choice(np.arange(len(self.train_labels)),self.batch_size,replace=False))
                data = self.train_data[idx]
                label = self.train_labels[idx]

                y_pred = self.sigmoid(np.dot(data,self.params))
                loss = self.cost(label,y_pred)

                gra = self.gradient(label,y_pred,data)
                self.params -= self.lr*gra

                self.lr *= (1. / (1. + self.decay * i))
            
            if self.print_every:
                if i%self.print_every == 0 or i == self.epoch-1:
                    print('Epoch : {}  Loss: {}'.format(i,loss))
    def predict(self,test_data):
        result = self.sigmoid(np.dot(test_data,self.params[1:])+self.params[0])
        result[result > 0.5 ] = 1
        result[result <= 0.5 ] = 0
        return result
    
    def evaluate(self,test_data,labels):
        accuracy = accuracy_score(self.predict(test_data),labels)
        return accuracy

def cross_validate(x_data,y_data,lr,lamda=0.2,epoch=10,k=4,batch_size=64,decay=10):
    if len(x_data)%k != 0:
        print('cant vsplit',len(x_data),' by ',k)
        return
    
    x_data_splitted = np.vsplit(x_data,k)
    y_data_splitted = np.vsplit(y_data,k)
    
    aggrigate_result = []
    for i in range(len(x_data_splitted)):
        train = []
        test = []
        items = [j for j in range(len(x_data_splitted)) if j !=i ]
        x_test = x_data_splitted[i]
        y_test = y_data_splitted[i]
        for item in items:
            if len(train) == 0:
                x_train = x_data_splitted[item]
                y_train = y_data_splitted[item]
            else:
                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)
                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)
        
        logistic = logisticregression(x_train,y_train,batch_size=batch_size,lamda=lamda,lr=lr,decay=decay,epoch=epoch,print_every=None)
        logistic.train()
        
        result = logistic.evaluate(x_test,y_test)
        aggrigate_result.append(result)
        
        value = sum(aggrigate_result)/len(aggrigate_result)
    return value

kmer_result = cross_validate(get_data(6)[:2000,:],get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)
count_result = cross_validate(get_count_grams(X_train_.Sequence.values,6),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)
tfidf_result = cross_validate(get_tf_idf_grams(X_train_.Sequence.values,6),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)

"""### Test which data is better representation

 The First Result is a simple logistic regression without any hyper-parameters search, making a baseline model. 
 
- Count-Vectorizer gives the best representation compare to the other two.
"""

final_value = {'K-mer':kmer_result,'Count-Vectorizer':count_result,'Tf-idf':tfidf_result}
final_value

for k,v in final_value.items():
    print('{} === {}'.format(k,v))

"""- Ridge Regression
- SVM
- Kernelized Method of the Variants

In the folowing lines of code  define a set of kernels that we will applied with ridge regression and SVM. 
"""

def sigma_from_median(X):
    pairwise_diff = X[:, :, None] - X[:, :, None].T
    pairwise_diff *= pairwise_diff
    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))
    return np.median(euclidean_dist)

def gaussian_kernel(x, y, sigma=5.0):
    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))

def linear_kernel(x1, x2):
    return np.dot(x1, x2.T)

def polynomial_kernel(X1, X2, power=2):
    return np.power((1 + linear_kernel(X1, X2)),power)

def rbf_kernel(X1, X2, sigma=10):
    X2_norm = np.sum(X2 ** 2, axis = -1)
    X1_norm = np.sum(X1 ** 2, axis = -1)
    gamma = 1 / (2 * sigma ** 2)
    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))
    return K

"""All kernelized methods were derived in the class"""

class KernelMethodBase(object):
    kernels_ = {
        'linear': linear_kernel,
        'polynomial': polynomial_kernel,
        'rbf': rbf_kernel,
        'gaussian':gaussian_kernel
    }
    def __init__(self, kernel='linear', **kwargs):
        self.kernel_name = kernel
        self.kernel_function_ = self.kernels_[kernel]
        self.kernel_parameters = self.get_kernel_parameters(**kwargs)
        
    def get_kernel_parameters(self, **kwargs):
        params = {}
        if self.kernel_name == 'rbf' or self.kernel_name == 'gaussian':
            params['sigma'] = kwargs.get('sigma', None)
        if self.kernel_name == 'polynomial':
            params['power'] = kwargs.get('power', None)
        return params

    def fit(self, X, y, **kwargs):
        return self
        
    def decision_function(self, X):
        pass

    def predict(self, X):
        pass

"""### Kernel Ridge Regression
--------------------------------------------
"""

class KernelRidgeRegression(KernelMethodBase):
    '''
    Kernel Ridge Regression
    '''
    def __init__(self, lambd=0.1, **kwargs):
        self.lambd = lambd
        # Python 3: replace the following line by
        # super().__init__(**kwargs)
        super(KernelRidgeRegression, self).__init__(**kwargs)

    def fit(self, X, y, sample_weights=None):
        n, p = X.shape
        assert (n == len(y))
    
        self.X_train = X
        self.y_train = y
        
        if sample_weights is not None:
            w_sqrt = np.sqrt(sample_weights)
            self.X_train = self.X_train * w_sqrt[:, None]
            self.y_train = self.y_train * w_sqrt
        
        A = self.kernel_function_(X,X,**self.kernel_parameters)
        A[np.diag_indices_from(A)] = np.add(A[np.diag_indices_from(A)],n*self.lambd)
        # self.alpha = (K + n lambda I)^-1 y
        self.alpha = np.linalg.solve(A , self.y_train)

        return self
    
    def decision_function(self, X):
        K_x = self.kernel_function_(X,self.X_train, **self.kernel_parameters)
        return K_x.dot(self.alpha)
    
    def predict(self, X):
        return self.decision_function(X)

"""### SVM with all the kernels defined above.
-----------------------------------------------------

<!-- - After training, we realized that the linear kernel with the k-mer data was giving the best result(65% on cross validation). -->
"""

class KernelSVM(KernelMethodBase):
    def __init__(self, C=0.1, **kwargs):
        self.C = C
        # Python 3: replace the following line by
        # super().__init__(**kwargs)
        super(KernelSVM, self).__init__(**kwargs)
        
    def cvxopt_qp(self,P, q, G, h, A, b):
        P = .5 * (P + P.T)
        cvx_matrices = [
            cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] 
        ]
        #cvxopt.solvers.options['show_progress'] = False
        solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})
        return np.array(solution['x']).flatten()
    
    def svm_dual_soft_to_qp_kernel(self,K, y, C=1):
        n = K.shape[0]
        assert (len(y) == n)

        # Dual formulation, soft margin
        # P = np.diag(y) @ K @ np.diag(y)
        P = np.diag(y).dot(K).dot(np.diag(y))
        # As a regularization, we add epsilon * identity to P
        eps = 1e-12
        P += eps * np.eye(n)
        q = - np.ones(n)
        G = np.vstack([-np.eye(n), np.eye(n)])
        h = np.hstack([np.zeros(n), C * np.ones(n)])
        A = y[np.newaxis, :]
        b = np.array([0.])
        return P, q, G, h, A.astype(float), b


    def fit(self, X, y, tol=1e-8):
        n, p = X.shape
        assert (n == len(y))
    
        self.X_train = X
        self.y_train = y
        
        # Kernel matrix
        K = self.kernel_function_(
            self.X_train, self.X_train, **self.kernel_parameters)
        
        # Solve dual problem
        self.alpha = self.cvxopt_qp(*self.svm_dual_soft_to_qp_kernel(K, y, C=self.C))
        
        # Compute support vectors and bias b
        sv = np.logical_and((self.alpha > tol), (self.C - self.alpha > tol))
        self.bias = y[sv] - K[sv].dot(self.alpha * y)
        self.bias = self.bias.mean()

        self.support_vector_indices = np.nonzero(sv)[0]

        return self
        
    def decision_function(self, X):
        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)
        return K_x.dot(self.alpha * self.y_train) + self.bias

    def predict(self, X):
        return np.sign(self.decision_function(X))

"""
<!-- ### We cross validated all of our submissions to avoid overfitting -->
"""

def cross_validate(x_data,y_data,model_name,lr=None,kernel=None,lambd=0.2,C=3,sigma=0.5,k=5,power=2):
    if len(x_data)%k != 0:
        print('cant vsplit',len(x_data),' by ',k)
        return

    x_data_splitted = np.vsplit(x_data,k)
    y_data_splitted = np.vsplit(y_data.reshape(-1,1),k)

    aggrigate_result = []
    for i in range(len(x_data_splitted)):
        train = []
        test = []
        items = [j for j in range(len(x_data_splitted)) if j !=i ]
        x_test = x_data_splitted[i]
        y_test = y_data_splitted[i]
        for item in items:
            if len(train) == 0:
                x_train = x_data_splitted[item]
                y_train = y_data_splitted[item]
            else:
                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)
                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)

        if model_name == 'KernelRidgeRegression':
            model = KernelRidgeRegression(
                    kernel=kernel,
                    lambd=lambd,
                    sigma=sigma,
                    power=power
                ).fit(x_train, y_train)
            result =sum(np.sign(model.predict(x_test))==y_test)/len(y_test)#roc_auc_score(np.sign(model.predict(x_test)),y_test) #

        elif model_name == 'KernelSVM':

            model = KernelSVM(C=C,
                              kernel=kernel,
                              lambd=lambd,
                              sigma=sigma,
                              power=power)
            model.fit(x_train, y_train.flatten())
            y_pred = model.predict(x_test)

            result = sum((y_pred.flatten()==y_test.flatten()))/len(y_test)

        else:
            print('wrong model_name')
            return 0

        aggrigate_result.append(result)

        value = sum(aggrigate_result)/len(aggrigate_result)
    return value

"""## [Optuna](https://optuna.org/) 
 
- we tried to get the best hyperparameters for the models we worked on using the hyperparameter optimization framework called Optuna.
"""

def objective(trial):
#     lambd = trial.suggest_float('lambd', 1e-5, 100.0)
    sigma = trial.suggest_float('sigma', 1e-5, 150)
    k =  trial.suggest_categorical('k', [4,5,8])
    C =  trial.suggest_float('C', 0.1,50)
#     power =  trial.suggest_int('power', 2,5)
    kmer_size =  trial.suggest_int('kmer_size', 3,8)
    kernel1 =  trial.suggest_categorical('kernel', ['linear','rbf','polynomial'])
#     model_name
    
    return cross_validate(get_data(kmer_size)[:2000,:],get_label(type=-1),model_name='KernelSVM',C=C,kernel=kernel1,lambd=0.01,k=k,sigma=sigma,power=1)

# cross_validate(X_train_vector, y,lamda=0.01,k=4)
import optuna

sampler = optuna.samplers.TPESampler()
study = optuna.create_study(sampler=sampler, direction='maximize')
df = study.optimize(func=objective, n_trials=50,show_progress_bar=True)

df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)
df.sort_values(by=['value']).head(5)

"""<!-- ## Finally we use our best parameters and train our model and submit -->"""

## Lets use the best parameter obtained from the optuna hyper-parameter tunning
X_train, X_test, y_train, y_test  = get_train_test(get_data(4)[:2000,:],get_label(type=-1).reshape(-1,1),p=0.01)


kernel = 'rbf'
power = 2
sigma = 26.49507399230858
C =  4.724702422629515,
lambd = 0.01
model = KernelSVM(C=C, kernel=kernel, sigma=sigma,lambd=lambd, power=power)
model.fit(X_train, y_train.flatten())
y_pred = model.predict(X_test)

sum(y_pred.flatten()==y_test.flatten())/len(y_test.flatten())

cross_validate(get_data(4)[:2000,:],get_label(type=-1),
               model_name='KernelSVM',
               kernel = 'rbf',
               k=4,
                power = 2,
                sigma = 26.49507399230858,
                C = 4.724702422629515,
                lambd = 0)

X_test_final  = model.predict(get_data(4)[2000:,:])
# submission = []
# for i in range(len(X_test_final)):
#     r1 = X_test_final[i]
#     if r1 == 1:
#         submission.append([int(r1)])
#     elif r1 == -1:
#         submission.append([0])
#     else:
#         print('problem')

# X_test_final  = model.predict(get_data(8)[2000:,:])

X_test_final.shape

submission = np.where(X_test_final == -1,0,1)

# Add the column of Ids
y_save = np.vstack([1 + np.arange(len(submission)), submission]).T
y_save[:10]

# Save as a csv file
np.savetxt('Yte.csv', y_save,
           delimiter=',', header='Id,Covid', fmt='%i', comments='')

# data=pd.read_csv("/content/prediction2.csv")
# data.shape

# data




